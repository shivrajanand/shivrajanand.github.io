<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Next Word Recommeder System</title>
    <link rel="stylesheet" href="../assets/css/globalblog.css">
    <!-- Load Prism CSS files with defer -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">

    <style>
        html {
            scroll-behavior: smooth;
            scroll-padding-top: 60px;
            /* Adjust based on your navbar height */
        }

        html,
        body {
            overflow-x: hidden;
            width: 100%;
        }

        /* General styling for the h1 tag */
        h1 {
            font-size: 3em;
            font-weight: bold;
            text-align: center;
            padding: 20px;
            margin: 10px 0;
            color: currentColor;
            border-radius: 20px;
            /* This makes the text color adapt to the current text color */
            transition: color 0.3s ease;
            /* Smooth transition for color change */
            /* Smooth transition for color change */
        }

        /* Light mode styles */
        @media (prefers-color-scheme: light) {
            h1 {
                color: #333;
                /* Dark color for text in light mode */
                background-color: #f9f9f9;
                /* Light background for light mode */
            }
        }

        /* Dark mode styles */
        @media (prefers-color-scheme: dark) {
            h1 {
                color: #f0f0f0;
                /* Light color for text in dark mode */
                background-color: #333;
                /* Dark background for dark mode */
            }
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5em;
            }
        }

        p {
            text-align: justify;
        }

        p a {
            color: #007bff;
        }

        p a:hover {
            color: #33a004;
        }

        /* Styles for the notebook */
        .notebook {
            width: 100%;
            margin: 0 auto;
            padding: 10px;
            /* Minimal padding */
            box-sizing: border-box;
        }

        /* Cell style inside the notebook */
        .cell {
            background-color: rgba(0, 0, 0, 0.05);
            border-radius: 5px;
            padding: 10px;
            /* Minimal padding */
            width: 100%;
            color: currentColor;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            /* Subtle shadow */
            margin: 5px 0;
            /* Minimal margin */
        }



        /* Code block styling (pre and code) */
        pre {
            padding: 5px;
            /* Minimal padding */
            border-radius: 4px;
            /* Smaller radius for a more compact look */
            margin: 5px 0;
            /* Minimal margin */
            font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;
            font-size: 15px;
            /* Slightly smaller font for mobile */
            line-height: 1.3;
            /* Tight line height for better space utilization */
            white-space: nowrap;
            /* Prevent wrapping of long lines of code */
            background-color: rgba(0, 0, 0, 0.05);
            color: #212121;
            border: 1px solid #ddd;
            overflow-x: auto;
            /* Horizontal scrolling */
            overflow-y: hidden;
            /* Disable vertical scroll if not needed */
        }

        pre code {
            font-weight: bolder;
        }

        pre table {
            border-collapse: collapse;
            width: 50%;
            font-family: inherit;
            font-size: inherit;
            text-align: left;
            margin: 20px 0;
            border: 1px solid #ddd;
        }

        pre table th,
        td {
            padding: 5px;
            border-right: 1px solid #ddd;
        }

        pre table th {
            border-bottom: 2px solid #dee2e6;
        }

        pre table tr {
            border-bottom: 1px solid #ddd;
        }

        pre table tr:last-child {
            border-bottom: none;
        }

        /* For dark mode */
        [data-theme="dark"] pre {
            background-color: rgba(0, 0, 0, 0.4);
            color: #f5f5f5;
            border: 1px solid #444;
        }

        /* Mobile view adjustments */
        @media (max-width: 600px) {
            .notebook {
                padding: 5px;
                /* Minimal padding for mobile */
            }

            .cell {
                padding: 8px;
                /* Slightly reduced padding for mobile */
            }

            pre {
                padding: 3px;
                /* Reduced padding for mobile */
                font-size: 12px;
                /* Smaller font for better fitting */
                margin: 3px 0;
                /* Minimal margin for mobile */
                max-height: none;
                /* No max-height to allow scrolling */
                overflow-x: auto;
                /* Enable horizontal scrolling */
                white-space: nowrap;
                /* Prevent line wrapping */
            }
        }

        /* Default styles for light mode */
        section h3 {
            font-size: 1.5em;
            font-weight: 600;
            color: #000000;
            margin: 10px 0;
            padding: 5px 0;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            border-bottom: 2px solid #e0e0e0;
            transition: color 0.3s ease, transform 0.3s ease, border-bottom-color 0.3s ease;
        }

        /* Hover effect */
        section h3:hover {
            color: #007bff;
            transform: translateX(5px);
            border-bottom-color: #007bff;
        }

        [data-theme="dark"] section h3 {
            color: #dbcaca;
            /* Lighter color for dark mode */
            border-bottom: 2px solid #444;
            /* Darker border for dark mode */
        }

        [data-theme="dark"] section h3:hover {
            color: #ff6347;
            /* Change color to a warm color (e.g., tomato) for dark mode hover */
            transform: translateX(5px);
            /* Slight movement to the right on hover */
            border-bottom-color: #ff6347;
            /* Change border color to tomato on hover */
        }

        footer {
            background-color: #F2F0EF;
            color: #000000;
            text-align: center;
            padding: 20px 0;
            font-family: Arial, sans-serif;
        }

        [data-theme="dark"] footer {
            background-color: #1f2937;
            color: #f5f5f5;
        }

        .social-media h3 {
            font-size: 20px;
            margin-bottom: 10px;
            color: #000000;
        }

        [data-theme="dark"] .social-media h3 {
            color: #f5f5f5;
        }

        .icons {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-top: 10px;
        }

        .icons a {
            color: #000000;
            font-size: 24px;
            transition: transform 0.3s ease, color 0.3s ease;
        }

        [data-theme="dark"] .icons a {
            color: #f5f5f5;
        }

        .icons a:hover {
            transform: scale(1.2);
            color: #ffcc00;
            /* Change color on hover */
        }

        /* Individual colors for branding */
        .icons a:nth-child(1):hover {
            color: #E1306C;
        }

        /* Instagram */
        .icons a:nth-child(2):hover {
            color: #0077B5;
        }

        /* LinkedIn */
        .icons a:nth-child(3):hover {
            color: grey;
        }

        /* GitHub */
        .icons a:nth-child(4):hover {
            color: #20BEFF;
        }

        /* Kaggle */
        .icons a:nth-child(5):hover {
            color: #1DA1F2;
        }

        /* Twitter/X */
        .icons a:nth-child(6):hover {
            color: #34A853;
        }

        /* email */
        @media (max-width: 600px) {
            .icons {
                gap: 10px;
            }

            .icons a {
                font-size: 20px;
            }
        }
    </style>
</head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3MEXW2XNBM"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-3MEXW2XNBM');
</script>

<body>
    <div class="app">
        <!-- Mobile Nav Overlay -->
        <div id="navOverlay" class="nav-overlay hidden"></div>

        <!-- Navigation -->
        <nav id="sidebar" class="sidebar">
            <div class="nav-content">
                <button id="closeNav" class="close-nav">&times;</button>
                <h2 class="nav-title">Table of Contents</h2>
                <div class="chapters">
                    <div class="chapter">
                        <h2><a href="#chapter1">Introduction</a></h2>
                        <ul>
                            <li><a href="#aboutTheProject">Abstract</a></li>
                            <li><a href="#introductionToNextWordPrediction">Introduction to Next Word Prediction</a>
                            </li>
                            <li><a href="#problemStatement">Problem Statement</a></li>
                            <li><a href="#objectiveOfTheProject">Objective of the Project</a></li>
                        </ul>
                    </div>

                    <div class="chapter">
                        <h2><a href="#chapter2">Dataset and Data Preprocessing</a></h2>
                        <ul>
                            <li><a href="#datasetDescription">Dataset Description</a></li>
                            <li><a href="#dataCleaningAndPreprocessing">Data Cleaning and Preprocessing</a></li>
                        </ul>
                    </div>

                    <div class="chapter">
                        <h2><a href="#chapter3">N-gram Based Approach</a></h2>
                        <ul>
                            <li><a href="#understandingNgram">Understanding N-gram Model</a></li>
                            <li><a href="#implementation">Implementation</a></li>
                            <li><a href="#samplePredictions">Sample Predictions</a></li>
                            <li><a href="#limitations">Limitations of N-gram Approach</a></li>
                        </ul>
                    </div>


                    <div class="chapter">
                        <h2><a href="#chapter4">Results and Analysis</a></h2>
                        <ul>
                            <li><a href="#modelPerformance">Model Performance</a></li>
                            <li><a href="#samplePredictions">Sample Predictions</a></li>
                            <li><a href="#challengesFaced">Challenges Faced</a></li>
                        </ul>
                    </div>

                    <div class="chapter">
                        <h2><a href="#chapter5">Applications and Future Scope</a></h2>
                        <ul>
                            <li><a href="#realWorldApplications">Real-World Applications</a></li>
                            <li><a href="#futureImprovements">Future Improvements</a></li>
                        </ul>
                    </div>

                    <div class="chapter">
                        <h2><a href="#chapter6">Conclusion</a></h2>
                    </div>

                    <div class="chapter">
                        <h2><a href="#chapter7">References and Resources</a></h2>
                    </div>


                </div>
            </div>
        </nav>


        <!-- Main Content -->
        <div class="main-content">
            <!-- Header -->
            <header class="header">
                <button id="menuButton" class="menu-button">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
                        stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <line x1="4" x2="20" y1="12" y2="12" />
                        <line x1="4" x2="20" y1="6" y2="6" />
                        <line x1="4" x2="20" y1="18" y2="18" />
                    </svg>
                </button>

                <button id="themeToggle" class="theme-toggle">
                    <svg class="sun-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="4" />
                        <path d="M12 2v2" />
                        <path d="M12 20v2" />
                        <path d="m4.93 4.93 1.41 1.41" />
                        <path d="m17.66 17.66 1.41 1.41" />
                        <path d="M2 12h2" />
                        <path d="M20 12h2" />
                        <path d="m6.34 17.66-1.41 1.41" />
                        <path d="m19.07 4.93-1.41 1.41" />
                    </svg>
                    <svg class="moon-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z" />
                    </svg>
                </button>

                <div class="right-buttons">
                    <a href="https://shivrajanand.github.io" class="btn">PORTFOLIO</a>
                </div>
            </header>

            <!-- Content -->
            <main class="content">
                <article class="article">
                    <h1>Next Word Recommender System using Probabilistic Models</h1>

                    <section id="chapter1">
                        <h2>Introduction</h2>
                        <h3 id="aboutTheProject">Abstract</h3>
                        <p>
                            Next Word Prediction is an elementary problem in Natural Language Processing (NLP) that is
                            used in search engines, text editors, and AI writing assistants. In this blog, a
                            probabilistic N-gram strategy to predict the next word of a sentence by statistical language
                            modeling is discussed. The N-gram model relies on word frequency probabilities rather than
                            deep learning-based approaches to produce predictions with efficient computations.
                        </p>
                        <p>
                            This project was done as a part of my 7th-semester B.Tech internship at Internshala, where I
                            implemented a Next Word Prediction system using data preprocessing, N-gram probability
                            calculations, and text-based evaluations. The blog includes the significance of Next Word
                            Prediction, processing the dataset, implementation details, and example predictions.
                            Further, we also present the drawbacks of N-gram models, including their reliance on
                            training data and absence of contextual knowledge, as well as some possible enhancements
                            with smoothing methods and hybrid models.
                        </p>
                        <p>
                            This blog is a helpful guide for anyone wanting to create a simple yet useful Next Word
                            Prediction system based on traditional probabilistic techniques.
                        </p>
                        <p>
                            You can access the entire project <a
                                href="https://www.kaggle.com/code/shivrajanandai/next-word-recommender-system"><strong>from
                                    this kaggle link</strong></a>. Also go through my other works from <a
                                href="https://shivrajanand.github.io/pages/blog.html"><strong>here</strong></a>.
                        </p>


                        <h3 id="introductionToNextWordPrediction">Introduction to Next Word Prediction</h3>
                        <p>As digital communication has expanded at a tremendous pace, Next Word Prediction is now a
                            vital feature in contemporary text-based programs. You type on a smartphone keypad, you
                            search using an engine, or you write emails, predictive text assists in making typing
                            faster, more accurate, and convenient for the user.</p>

                        <p>Next Word Prediction is one of the most basic problems of Natural Language Processing (NLP),
                            in which the task is to predict the next most likely word from the context provided. There
                            are multiple methods to address this problem, from rule-based models to powerful deep
                            learning methodologies. In our project, we work with a probabilistic N-gram approach, which
                            takes advantage of statistical patterns in texts to predict the next word at a low
                            computational cost.</p>

                        <p>The N-gram model is an efficient and easy technique for language modeling. It determines the
                            probability of a word in a sequence based on the words that precede it. The method is highly
                            used because of its low computational complexity and readability, making it an ideal
                            technique for scenarios where deep learning cannot be used.</p>
                        <p>
                            In this blog, we shall discuss:
                        <ul style="list-style-type: circle; margin-left: 20px;">
                            <li>The significance and usage of Next Word Prediction</li>
                            <li> How N-gram models function and their application</li>
                            <li>Example predictions and limitations</li>
                        </ul>
                        </p>
                        <h3 id="problemStatement">Problem Statement</h3>
                        <p><strong>Develop a next word recommendation system which should take in a seed text from the
                                user as input and predict the next relevant word.</strong></p>
                        <h3 id="objectiveOfTheProject">Objective of the Project</h3>
                        <p>The objective of this project is to create a Next Word Recommendation System that accepts a
                            user-provided text input and predicts the most appropriate next word. Rather than using
                            sophisticated machine learning models, this project emphasizes a probabilistic method based
                            on N-grams, which utilizes statistical language patterns to make predictions.</p>
                        <p>Through the construction of this system, the goal is to have a thorough, hands-on
                            comprehension of how next-word prediction operates at its core. This project enables us to
                            delve into language modeling, probability distributions, and text processing without having
                            to explicitly train with sophisticated ML algorithms. It is a stepping stone for
                            comprehending both classical NLP methods and their practical applications in predictive text
                            systems.</p>
                    </section>
                    <section id="chapter2">
                        <h2 id="chapter2">Dataset and Data Preprocessing</h2>

                        <h3 id="datasetDescription">Dataset Description</h3>
                        <p>The Taskmaster Conversational Dataset, released in 2019, is a 64,777 conversational dialogue
                            dataset and has been proposed for the training and testing of dialogue systems as well as
                            next-word prediction models to offer authentic, goal-driven real-world conversations
                            spanning various domains.</p>
                        <p>
                            Features:
                        <ul style="margin-left: 1vh;">
                            <li><strong>Size</strong>: 64,777 dialogues</li>
                            <li><strong>Type</strong>: Task-based, goal-oriented dialogues</li>
                            <li><strong>Domains included:</strong></li>
                            <ul style="margin-left: 1.5vh; list-style-type:num">
                                <li>Ordering Pizza 🍕</li>
                                <li>Setting Up a Ride Service 🚖</li>
                                <li>Making Restaurant Reservations 🍽️</li>
                                <li>Creating Auto Repair Appointments🚗</li>
                                <li>Ordering Coffee Drinks ☕</li>
                                <li>Ordering Movie Tickets 🎬</li>
                            </ul>
                        </ul>
                        </p>
                        <p>Each of the conversations in the dataset is an actual interaction between a user and an
                            automated system or a human helper and thus is perfect for learning natural language
                            understanding, conversational AI, and predictive text models.</p>
                        <p>For this project, the data is utilized to train a probabilistic Next Word Prediction system
                            on an N-gram model that learns patterns in language from such task-oriented dialogues. The
                            structured form of the data allows for insight into how individuals convey information in
                            service-based interactions and enables more informed and context-savvy text predictions.</p>
                        <h3 id="dataCleaningAndPreprocessing">Data Cleaning and Preprocessing</h3>
                        <h4>Loading the dataset</h4>
                        <div class="notebook">
                            <div class="cell">
                                <pre><code>with open("/kaggle/input/task-master-conversational-dataset/dialogs_dataset", "rb") as f: <br>&emsp13;&emsp13; dialogs = pickle.load(f)</code></pre>
                            </div>
                            <div class="cell">
                                <pre><code>random.sample(dialogs_clean, 10)</code></pre>
                                <pre>
                                    ["I'm in Orlando Florida", <br>
                                    "OK, I'll do that",<br>
                                    'No that is all',<br>
                                    'You covered it all! Thanks!',<br>
                                    "I'll take that please",<br>
                                    ' Can you add a cheese pizza to that, too, actually? No toppings',<br>
                                    'No that is all for now',<br>
                                    ' I need you to schedule an appointment for my vehicle?',<br>
                                    "I would like to order a pizza from Papa John's",<br>
                                    "Okay I'll be there thank you"]</pre>
                            </div>
                        </div>
                        <h4>cleaning the dataset</h4>
                        <p>Everything except alphabets and white spaces is removed</p>
                        <div class="notebook">
                            <div class="cell">
                                <pre><code>
                                    dialogs_clean = []<br>
                                    for i in dialogs: <br>
                                        &emsp13;&emsp13;i = re.sub("[^a-zA-Z' ]", "", i)<br>
                                        &emsp13;&emsp13;i = i.lower()<br>
                                        &emsp13;&emsp13;dialogs_clean.append(i)
                                </code></pre>
                            </div>

                            <div class="cell">
                                <pre><code>random.sample(dialogs_clean, 10)</code></pre>
                                <pre>
                                    [' how much are the ticket prices',<br>
                                     'can i get a pepperoni and pineapple pizza',<br>
                                     " and the driver's name",<br>
                                     'large  please',<br>
                                     'just four of us',<br>
                                     "that's perfect thank you",<br>
                                     'do they have buffet',<br>
                                     "yes that's all i need",<br>
                                     'hello there i would like to order an ultimate pepperoni ',<br>
                                     'i need new front tires but my rear tires are fine']</pre>
                            </div>
                            <h4>Creating the vocabulary</h4>
                            <p><strong>Vocabulary</strong> is the set of all unique words in a corpus(dataset).
                                Extracting this is necessary to calculate probabilities of n-gram I will obtain in
                                upcoming section.</p>

                            <div class="cell">
                                <pre><code>
                                    all_words = " ".join(dialogs_clean).split() <br>
                                    words_dict = {} <br>
                                    for word in all_words: <br>
                                        &emsp13;&emsp13;for word in all_words: <br>
                                            &emsp13;&emsp13;&emsp13;&emsp13;if word not in words_dict: <br>
                                        &emsp13;&emsp13;else: <br>
                                            &emsp13;&emsp13;&emsp13;&emsp13;words_dict[word] = 1

                                            &emsp13;&emsp13;for word in all_words: <br>
                                            &emsp13;&emsp13;&emsp13;&emsp13;else: <br>
                                        &emsp13;&emsp13;else: <br>
                                            &emsp13;&emsp13;&emsp13;&emsp13;words_dict[word] += 1
                                </code></pre>
                            </div>

                            <h4>Creating Word Count Dataframe</h4>
                            <p>Word count dataframe is a 2D table with two colums, column 1 consists of all the unique
                                words (vocabulary) and column 2 consists of number of occurences of the unique word in
                                the dataset.</p>

                            <div class="cell">
                                <pre><code>
                                    words_df = pd.DataFrame({'word':list(words_dict.keys()), 'count':list(words_dict.values())}) <br>
                                    words_df = words_df.sort_values(by = ['count']) <br>
                                    words_df.reset_index(drop=True, inplace=True)
                                </code></pre>
                            </div>

                            <div class="notebook">
                                <div class="cell">
                                    <pre><code>words_df.head()</code></pre>
                                    <pre>
                                        <table>
                                            <tr>
                                                <th></th>
                                                <th>word</th>
                                                <th>count</th>
                                            </tr>
                                            <tr>
                                                <td>0</td>
                                                <td>uppermiddle</td>
                                                <td>1</td>
                                            </tr>
                                            <tr>
                                                <td>1</td>
                                                <td>shoots</td>
                                                <td>1</td>
                                            </tr>
                                            <tr>
                                                <td>2</td>
                                                <td>geesh</td>
                                                <td>1</td>
                                            </tr>
                                            <tr>
                                                <td>3</td>
                                                <td>andrea</td>
                                                <td>1</td>
                                            </tr>
                                            <tr>
                                                <td>4</td>
                                                <td>precice</td>
                                                <td>1</td>
                                            </tr>
                                        </table>
                                    </pre>

                                </div>

                                <div class="cell">
                                    <pre><code>words_df.tail()</code></pre>
                                    <pre>
                                        <table>
                                            <tr>
                                                <th></th>
                                                <th>word</th>
                                                <th>count</th>
                                            </tr>
                                            <tr>
                                                <td>11142</td>
                                                <td>you</td>
                                                <td>11909</td>
                                            </tr>
                                            <tr>
                                                <td>11143</td>
                                                <td>a</td>
                                                <td>13380</td>
                                            </tr>
                                            <tr>
                                                <td>11144</td>
                                                <td>to</td>
                                                <td>14000</td>
                                            </tr>
                                            <tr>
                                                <td>11145</td>
                                                <td>the</td>
                                                <td>15406</td>
                                            </tr>
                                            <tr>
                                                <td>11146</td>
                                                <td>i</td>
                                                <td>19654</td>
                                            </tr>
                                        </table>
                                    </pre>
                                </div>
                            </div>


                    </section>

                    <section id="chapter3">
                        <h2 id="chapter3">N-gram Based Approach</h2>
                        <h3 id="understandingNgram">Understanding N-gram Model</h3>
                        <h3 id="implementation">Implementation</h3>
                        <h3 id="samplePredictions">Sample Predictions</h3>
                        <h3 id="limitations">Limitations of N-gram Approach</h3>
                    </section>

                    <section id="chapter4">
                        <h2 id="chapter4">Results and Analysis</h2>
                        <h3 id="modelPerformance">Model Performance</h3>
                        <h3 id="samplePredictions">Sample Predictions</h3>
                        <h3 id="challengesFaced">Challenges Faced</h3>
                    </section>

                    <section id="chapter5">
                        <h2 id="chapter5">Applications and Future Scope</h2>
                        <h3 id="realWorldApplications">Real-World Applications</h3>
                        <h3 id="futureImprovements">Future Improvements</h3>
                    </section>
                    <section id="chapter6">
                        <h2 id="chapter6">Conclusion</h2>
                    </section>
                    <section id="chapter7">
                        <h2 id="chapter7">References and Resources</h2>
                    </section>
                </article>

            </main>

            <footer>
                <div class="social-media">
                    <h3>Follow Me</h3>
                    <div class="icons">
                        <a href="https://www.instagram.com/shivrajanandai/" target="_blank" rel="noopener noreferrer">
                            <i class="fab fa-instagram"></i>
                        </a>
                        <a href="https://www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=shivrajanand"
                            target="_blank" rel="noopener noreferrer">
                            <i class="fab fa-linkedin"></i>
                        </a>
                        <a href="https://www.github.com/shivrajanand" target="_blank" rel="noopener noreferrer">
                            <i class="fab fa-github"></i>
                        </a>
                        <a href="https://www.kaggle.com/shivrajanandai" target="_blank" rel="noopener noreferrer">
                            <i class="fab fa-kaggle"></i>
                        </a>
                        <a href="https://x.com/shivrajanand_ai" target="_blank" rel="noopener noreferrer">
                            <i class="fab fa-twitter"></i>
                        </a>

                        <a href="https://mailto::shivrajanand022002@gmail.com" target="_blank"
                            rel="noopener noreferrer">
                            <i class="fa fa-envelope"></i>
                        </a>

                    </div>
                </div>
            </footer>
        </div>
    </div>

    <!-- Load scripts with defer -->
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script defer src="../assets/js/globalblog.js"></script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>


    <!-- Fallback for Prism if CDN fails -->
    <script>
        window.addEventListener('load', function () {
            if (typeof Prism === 'undefined') {
                console.error('Prism failed to load');
                // Add a class to show code without highlighting
                document.querySelectorAll('pre code').forEach(block => {
                    block.classList.add('no-highlight');
                });
            }
        });
    </script>


</body>

</html>